\documentclass{article} % For LaTeX2e
\usepackage{nips13submit_e,times}
\usepackage{hyperref}
\usepackage{url}
\bibliographystyle{plain}
%\documentstyle[nips13submit_09,times,art10]{article} % For LaTeX 2.09


\title{Learning Human Activities and Object Functionalities through Conditional Random Fields}


\author{
Nakul Gopalan\\
Department of Computer Science\\
Brown University\\
Providence, RI 02912 \\
\texttt{ngopalan@cs.brown.edu} \\
\And
Jun Ki~Lee\\
Department of Computer Science\\
Brown University\\
Providence, RI 02912 \\
\texttt{jklee@cs.brown.edu} \\
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\nipsfinalcopy % Uncomment for camera-ready version

\begin{document}


\maketitle

\begin{abstract}
Recognizing a human or animal activity is a skill that humans learn early in life. Activity recognition helps humans in predicting next steps of the activitiy in question and also in planning other activities with respect to the recognized activity. Our objective is to recognize human activities using machine learning, to predict next steps of an action, or provide help using robots or other interfaces, or help recognizing problems in the activity being performed. Specifically of interest to us are the human activities being performed on a table-top, where the human can be observed and helped by a robot. We plan to use a dataset from \cite{koppula2013detectingactivitiesrgbd} to learn a Graphical Model with temporal and spatial structure, which can then be used to predict the action being performed. As a baseline we have results of a bag of words classification of the $10$ activities, which yields a result of $67\%$.
\end{abstract}

\section{Introduction}
% why problem important, how object information and use can help in recognizing an action

\section{Background}
% what has been tried previously why this work interests us as roboticists who work on the table top environment.....

\section{Dataset}
We explored data sets with activity labels and corresponding skeletal trajectories. Humans frequently perform activities using objects, especially in table-top scenarios. The dataset from \cite{koppula2013detectingactivitiesrgbd} was constructed keeping this relationship in mind. The raw data consists of the RGB-D frames from the scenes of humans performing activities and human skeletal poses from the OpenNI NITE tracker \cite{PrimeSense2010}. The skeletal poses are not precise and come with confidence intervals. The labels on the data are related to both the objects present in the scene and the activities involved.	


The data consisits of skeletal poses of human subjects performing activities, but along with this the dataset also has lables, positions and poses for all objects present in the scene. The activities present in the dataset are: cleaning, stacking objects, unstacking objects, eating, making cereal, taking medicine, microwaving food, arranging objects, taking food and picking objects. The activities themselves have been broken down into subactivities like placing, reaching, grabbing, which are labelled framewise.  

\section{Methods}



\bibliography{ref}


\end{document}
